{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Word Clouds\n",
    "\n",
    "In this lab notebook, we will learn how to visualize word clouds. Word clouds are useful to give an idea of a body of text at a glance; we instantly see which words are used the most in the text. By using **size as the visual channel** to represent the frequency of the word, we can utilize human visual perception to perceive the relative frequencies of the words at an instant. Now, we will see how to create a simple word cloud. Later in the practice, we'll see how to create interactive visualizations with word clouds. \n",
    "\n",
    "We will use ```tm``` text mining library and ```SnowBallC``` word stemming library to process text. \n",
    "\n",
    "First we need to read our text data from the file, and then convert it into a **corpus** to process it. **Run the following code cells in the notebook. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"tm\") # text mining library\n",
    "library(\"SnowballC\") # word stemmer\n",
    "library(\"wordcloud\") # wordcloud vis\n",
    "library(\"RColorBrewer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the text file \n",
    "filePath <- \"HuckFinn_chapters1-3.txt\"\n",
    "text <- readLines(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn text into a corpus\n",
    "docs <- Corpus(VectorSource(text))\n",
    "# Look at the corpus\n",
    "inspect(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you can see the contents of the corpus. \n",
    "We need to process this text before we create our word cloud. \n",
    "We need to remove things that are not useful such as capitalization, white space, punctuations, and stopwords. \n",
    "\n",
    "**Stopwords** are those that are most common in a language, and usually are filtered out before text mining (words such as an, are, as, for, the, etc.).\n",
    "\n",
    "**Text stemming** is the process of reducing inflected or derived words to their word stem or root form; such as thinking -> think, cats -> cat, connected -> connect. Text stemming may not always produce good results, whether you should use it should be decided on a case by case basis. \n",
    "\n",
    "Let's see how we do these in R: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some preprocessing first\n",
    "\n",
    "# To lower case \n",
    "docs <- tm_map(docs, content_transformer(tolower))\n",
    "# Remove english common stopwords\n",
    "docs <- tm_map(docs, removeWords, stopwords(\"english\"))\n",
    "# Eliminate extra white spaces\n",
    "docs <- tm_map(docs, stripWhitespace)\n",
    "# Text stemming\n",
    "docs <- tm_map(docs, stemDocument)\n",
    "# Remove punctuations\n",
    "docs <- tm_map(docs, removePunctuation)\n",
    "\n",
    "# Inspect again\n",
    "inspect(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the text is filtered and ready for mining. As a result of stemming, some words are converted to non-words; some words were left unstemmed. We can visualize both with and without stemming to see if it makes any meaningful difference. \n",
    "\n",
    "Before we can create the word cloud, we first need to create a **frequency table** for the words. This will be the word counts in the corpus. We use ```TermDocumentMatrix``` for that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create frequencies of the words \n",
    "dtm <- TermDocumentMatrix(docs)\n",
    "\n",
    "# Convert it to a matrix and sort w.r.t. freq.s\n",
    "m <- as.matrix(dtm)\n",
    "v <- sort(rowSums(m), decreasing=TRUE)\n",
    "# Convert to a data frame \n",
    "d <- data.frame(word = names(v), freq=v)\n",
    "# Print the data frame \n",
    "head(d, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we can use the wordcloud to visualize these words. ** Look at the comments in the code to see the options to the ```wordcloud```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word cloud visualization \n",
    "# Set the random number generator \n",
    "set.seed(1234)\n",
    "# inputs are the words, frequencies, minimum freq of a word to show, max. number of words to show. \n",
    "# rot.per is the percentage of the rotated words in the vis; we don't want any, so it's zero. \n",
    "wordcloud(words = d$word, freq = d$freq, min.freq = 5,\n",
    "          max.words=100, random.order=FALSE, rot.per=0, \n",
    "          colors=brewer.pal(8, \"Dark2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are still some words that are not very useful for analysis. We can create our own list of stopwords and remove them from the corpus. Here is how: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify your own stopwords as a character vector, and rerun on the docs. \n",
    "docs <- tm_map(docs, removeWords, c(\"said\", \"got\",\"went\",\"come\",\"dont\",\"didnt\",\"wouldnt\",\"couldnt\",\"well\",\"get\",\"want\",\"say\",\"told\",\"know\",\"see\",\"must\",\"make\",\"like\",\"one\",\"thing\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rerun the code \n",
    "dtm <- TermDocumentMatrix(docs)\n",
    "m <- as.matrix(dtm)\n",
    "v <- sort(rowSums(m),decreasing=TRUE)\n",
    "d <- data.frame(word = names(v), freq=v)\n",
    "head(d, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud(words = d$word, freq = d$freq, min.freq = 10,\n",
    "          max.words=100, random.order=FALSE, rot.per=0, \n",
    "          colors=brewer.pal(8, \"Dark2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the practice, we will see how to create a word cloud and remove words interactively to analyze the text. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
